from fastapi import FastAPI, File, UploadFile, Form, Request
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
import shutil, os, subprocess
from uuid import uuid4
from pathlib import Path

from azure_eval import assess_pronunciation
from voice_model import evaluate_wav

# ğŸ“Œ ë¬¸ì¥ ë²ˆí˜¸ â†’ ì‹¤ì œ ë¬¸ì¥ í…ìŠ¤íŠ¸ ë§¤í•‘
REFERENCE_TEXTS = {
    "1": "He was pressing beyond the limits of his vocabulary.",
    "2": "But he reconciled himself to it by an act of faith.",
    "3": "Each insult added to the value of the claim.",
    "4": "There is more behind this than a mere university ideal.",
    "5": "You're a devil for fighting and will surely win."
}

# âœ… m4a â†’ wav ë³€í™˜ í•¨ìˆ˜
def convert_to_wav(input_path: str, output_path: str):
    subprocess.run(["ffmpeg", "-y", "-i", input_path, output_path], check=True)

# ê¸°ë³¸ ì„¤ì •
app = FastAPI()
UPLOAD_DIR = "uploads"
IMAGE_DIR = "static/image"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(IMAGE_DIR, exist_ok=True)

# Static mount
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

@app.get("/", response_class=HTMLResponse)
def index():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return f.read()

@app.post("/analyze/", response_class=HTMLResponse)
async def analyze(
    request: Request,
    file: UploadFile = File(...),
    reference: str = Form(...),   # ğŸ‘‰ "1" ~ "5" í˜•íƒœ
    mel_path: str = Form(...)     # ğŸ‘‰ "spectrogram/L1/1_L1_mels.npy"
):
    session_id = str(uuid4())[:8]
    original_path = os.path.join(UPLOAD_DIR, f"{session_id}_{file.filename}")

    # ğŸ”¹ 1. íŒŒì¼ ì €ì¥
    with open(original_path, "wb") as f_out:
        shutil.copyfileobj(file.file, f_out)

    # ğŸ”¹ 2. í™•ì¥ì ê²€ì‚¬ í›„ wavë¡œ ë³€í™˜
    ext = Path(file.filename).suffix.lower()
    if ext != ".wav":
        wav_path = os.path.join(UPLOAD_DIR, f"{session_id}.wav")
        convert_to_wav(original_path, wav_path)
    else:
        wav_path = original_path

    # ğŸ”¹ 3. ê¸°ì¤€ ë¬¸ì¥ í…ìŠ¤íŠ¸ ë§¤í•‘
    reference_text = REFERENCE_TEXTS.get(reference, "")

    # ğŸ”¹ 4. Azure í‰ê°€
    azure_result = assess_pronunciation(wav_path, reference_text)

    # ğŸ”¹ 5. ì¤€ì„œ ëª¨ë¸ í‰ê°€
    similarity_score, feedback, plot_path, highlighted_sentence = evaluate_wav(
        wav_path=wav_path,
        session_id=session_id,
        pron_json=azure_result,
        sentence=reference_text,
        l1_mel_path=mel_path
    )

    # ğŸ”¹ 6. ê²°ê³¼ ë Œë”ë§
    return templates.TemplateResponse("result.html", {
        "request": request,
        "azure": azure_result,
        "junseo": {
            "similarity_score": similarity_score,
            "intonation_feedback": feedback
        },
        "highlighted_text": highlighted_sentence,
        "intonation_plot": plot_path
    })
